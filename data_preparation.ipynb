{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363a078c-6808-4bf5-ad66-750c2047b5b4",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62614185-9ef7-461f-a03f-3722799697a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These two commands are needed\n",
    "# !pip install transformers\n",
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7336fa36-a5dc-43d9-976e-427a9e8c4e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a29510a-b6f4-492a-b028-0776461b1199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2024-06-29 01:02:52.485603: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-29 01:02:52.607489: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-29 01:02:53.304492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-06-29 01:02:53.304572: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-06-29 01:02:53.304577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "# import local scripts\n",
    "from data_loader import DatasetLoader\n",
    "from alignment_metrics import *\n",
    "from gpt2_model import GPT2Model\n",
    "\n",
    "# produce repeatable results\n",
    "np.random.seed(seed=42)\n",
    "transformers.set_seed(42)\n",
    "\n",
    "# enable CUDNN deterministic mode\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4173ef-0513-4bb0-a170-2129d03d67e2",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8d313-2265-4d12-8d46-b8f961cbc7e7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Below are the names of the datasets used by the authors to check if contrastive explanations identify linguistically appropriate evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb67dff-7496-415c-b1b2-978768144041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anaphor_agreement_datasets = [\"anaphor_gender_agreement\", \"anaphor_number_agreement\"]\n",
    "\n",
    "# not sure about the one below\n",
    "argument_structure_datasets = [\"animate_subject_passive\"]\n",
    "\n",
    "determiner_noun_agreement_datasets = [\n",
    "    \"determiner_noun_agreement_1\",\n",
    "    \"determiner_noun_agreement_2\",\n",
    "    \"determiner_noun_agreement_irregular_1\",\n",
    "    \"determiner_noun_agreement_irregular_2\",\n",
    "    \"determiner_noun_agreement_with_adj_2\",\n",
    "    \"determiner_noun_agreement_with_adj_irregular_1\",\n",
    "    \"determiner_noun_agreement_with_adj_irregular_2\",\n",
    "    \"determiner_noun_agreement_with_adjective_1\",\n",
    "    \"determiner_noun_agreement_with_adj_irregular_1\",\n",
    "    \"determiner_noun_agreement_with_adj_irregular_2\"\n",
    "]\n",
    "\n",
    "npi_licesing = [\n",
    "    \"npi_present_1\",\n",
    "    \"npi_present_2\"\n",
    "]\n",
    "\n",
    "subject_verb_agreement = [\n",
    "    \"distractor_agreement_relational_noun\"\n",
    "    \"irregular_plural_subject_verb_agreement_1\",\n",
    "    \"irregular_plural_subject_verb_agreement_2\",\n",
    "    \"regular_plural_subject_verb_agreement_1\",\n",
    "    \"regular_plural_subject_verb_agreement_2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89280074-a98f-410b-9bb6-db1882ec86da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_good</th>\n",
       "      <th>sentence_bad</th>\n",
       "      <th>field</th>\n",
       "      <th>linguistics_term</th>\n",
       "      <th>UID</th>\n",
       "      <th>simple_LM_method</th>\n",
       "      <th>one_prefix_method</th>\n",
       "      <th>two_prefix_method</th>\n",
       "      <th>lexically_identical</th>\n",
       "      <th>pair_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanda was respected by some waitresses.</td>\n",
       "      <td>Amanda was respected by some picture.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some lake was passed by some cashiers.</td>\n",
       "      <td>Some lake was passed by some phenomena.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa was kissed by the boys.</td>\n",
       "      <td>Lisa was kissed by the blouses.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amanda isn't respected by the children.</td>\n",
       "      <td>Amanda isn't respected by the cups.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The glove was noticed by some woman.</td>\n",
       "      <td>The glove was noticed by some mouse.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>This pork was taken by some guy.</td>\n",
       "      <td>This pork was taken by some fish.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Newspaper articles weren't scanned by the men.</td>\n",
       "      <td>Newspaper articles weren't scanned by the phot...</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Liam is talked about by the dancers.</td>\n",
       "      <td>Liam is talked about by the university.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Monet is sounded like by the man.</td>\n",
       "      <td>Monet is sounded like by the bread.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Paul was kissed by some girl.</td>\n",
       "      <td>Paul was kissed by some species.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>s-selection</td>\n",
       "      <td>animate_subject_passive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sentence_good  \\\n",
       "0          Amanda was respected by some waitresses.   \n",
       "1            Some lake was passed by some cashiers.   \n",
       "2                      Lisa was kissed by the boys.   \n",
       "3           Amanda isn't respected by the children.   \n",
       "4              The glove was noticed by some woman.   \n",
       "..                                              ...   \n",
       "995                This pork was taken by some guy.   \n",
       "996  Newspaper articles weren't scanned by the men.   \n",
       "997            Liam is talked about by the dancers.   \n",
       "998               Monet is sounded like by the man.   \n",
       "999                   Paul was kissed by some girl.   \n",
       "\n",
       "                                          sentence_bad   field  \\\n",
       "0                Amanda was respected by some picture.  syntax   \n",
       "1              Some lake was passed by some phenomena.  syntax   \n",
       "2                      Lisa was kissed by the blouses.  syntax   \n",
       "3                  Amanda isn't respected by the cups.  syntax   \n",
       "4                 The glove was noticed by some mouse.  syntax   \n",
       "..                                                 ...     ...   \n",
       "995                  This pork was taken by some fish.  syntax   \n",
       "996  Newspaper articles weren't scanned by the phot...  syntax   \n",
       "997            Liam is talked about by the university.  syntax   \n",
       "998                Monet is sounded like by the bread.  syntax   \n",
       "999                   Paul was kissed by some species.  syntax   \n",
       "\n",
       "    linguistics_term                      UID  simple_LM_method  \\\n",
       "0        s-selection  animate_subject_passive              True   \n",
       "1        s-selection  animate_subject_passive              True   \n",
       "2        s-selection  animate_subject_passive              True   \n",
       "3        s-selection  animate_subject_passive              True   \n",
       "4        s-selection  animate_subject_passive              True   \n",
       "..               ...                      ...               ...   \n",
       "995      s-selection  animate_subject_passive              True   \n",
       "996      s-selection  animate_subject_passive              True   \n",
       "997      s-selection  animate_subject_passive              True   \n",
       "998      s-selection  animate_subject_passive              True   \n",
       "999      s-selection  animate_subject_passive              True   \n",
       "\n",
       "     one_prefix_method  two_prefix_method  lexically_identical  pair_id  \n",
       "0                 True              False                False        0  \n",
       "1                 True              False                False        1  \n",
       "2                 True              False                False        2  \n",
       "3                 True              False                False        3  \n",
       "4                 True              False                False        4  \n",
       "..                 ...                ...                  ...      ...  \n",
       "995               True              False                False      995  \n",
       "996               True              False                False      996  \n",
       "997               True              False                False      997  \n",
       "998               True              False                False      998  \n",
       "999               True              False                False      999  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DatasetLoader()\n",
    "data = pd.DataFrame(data_loader.load_data(argument_structure_datasets[0])[\"train\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94351e1-83f3-40ae-a8c0-82dc2e0d2ed8",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### 2. Prepare anaphor agreement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09668026-f097-478e-9bf3-399618d4b2a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_main_verb(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    main_verbs = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            main_verbs.append(token.text)\n",
    "\n",
    "    assert len(main_verbs) == 1\n",
    "\n",
    "    return main_verbs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd0f7f0-c339-4d5f-abfd-96be969530e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 219.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pairs with different number of words: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_sentences_data = []\n",
    "good_bad_sentences = data[[\"sentence_good\", \"sentence_bad\"]].to_numpy()\n",
    "dif_lengths = 0\n",
    "\n",
    "for good_sentence, bad_sentence in tqdm(good_bad_sentences):\n",
    "    # remove characters that are not letters or apostrophes and replace contractions\n",
    "    good_sentence_cleaned = re.sub(r\"[^\\w\\s']\", \"\", good_sentence).replace(\"n't\", \" not\")\n",
    "    bad_sentence_cleaned = re.sub(r\"[^\\w\\s']\", \"\", bad_sentence).replace(\"n't\", \" not\")\n",
    "\n",
    "    # tokenize the text\n",
    "    good_sentence_tokenized = good_sentence_cleaned.split(\" \")\n",
    "    bad_sentence_tokenized = bad_sentence_cleaned.split(\" \")\n",
    "\n",
    "    # consider only pairs of sentences with the same number of words\n",
    "    number_considered_words = min(len(good_sentence_tokenized), len(bad_sentence_tokenized))\n",
    "    if len(good_sentence_tokenized) != len(bad_sentence_tokenized):\n",
    "        dif_lengths += 1\n",
    "\n",
    "    good_sentence_tokenized = good_sentence_tokenized[:number_considered_words]\n",
    "    bad_sentence_tokenized = bad_sentence_tokenized[:number_considered_words]\n",
    "\n",
    "    # get the main verb of the sentence\n",
    "    main_verb = get_main_verb(good_sentence)\n",
    "\n",
    "    # get the common part of the two sentences (until the first different word)\n",
    "    same_tokens = np.array(good_sentence_tokenized) == np.array(bad_sentence_tokenized)\n",
    "    index_first_diff_token = np.where(same_tokens == False)[0][0]\n",
    "\n",
    "    common_sentence_tokenized = good_sentence_tokenized[:index_first_diff_token]\n",
    "    common_sentence = \" \".join(common_sentence_tokenized)\n",
    "\n",
    "    # construct an array where 1s represent the position of the target word\n",
    "    known_evidence = np.zeros(len(common_sentence_tokenized))\n",
    "    evidence_index = np.where(np.array(common_sentence_tokenized) == main_verb)[0][0]\n",
    "    known_evidence[evidence_index] = 1\n",
    "\n",
    "    # get the correct and foil words\n",
    "    correct_word = good_sentence_tokenized[index_first_diff_token]\n",
    "    foil_word = bad_sentence_tokenized[index_first_diff_token]\n",
    "\n",
    "    extracted_sentences_data.append([known_evidence, common_sentence, correct_word, foil_word])\n",
    "\n",
    "print(f\"The number of pairs with different number of words: {dif_lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "172bda0c-0298-48fc-83d4-fd09b24049f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt2model = GPT2Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa18c957-60e5-404b-8ed5-c693e1e58564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_evidence_with_tokenization(space_tokenization, gpt_tokenization, known_evidence):\n",
    "    # this function adds 0s or 1s in the known evidence to match the gpt tokens\n",
    "\n",
    "    space_tokenization_index = 0\n",
    "    updated_known_evidence = []\n",
    "    accumulated_string = gpt_tokenization[0]\n",
    "\n",
    "    for gpt_tokenization_index, gpt_token in enumerate(gpt_tokenization[1:]):\n",
    "        if accumulated_string == space_tokenization[space_tokenization_index]:\n",
    "            updated_known_evidence.append(known_evidence[space_tokenization_index])\n",
    "            gpt_tokenization_index += 1\n",
    "            accumulated_string = gpt_tokenization[gpt_tokenization_index]\n",
    "            space_tokenization_index += 1\n",
    "\n",
    "        else:\n",
    "            accumulated_string += gpt_token\n",
    "            updated_known_evidence.append(known_evidence[space_tokenization_index])\n",
    "\n",
    "    updated_known_evidence.append(known_evidence[space_tokenization_index])\n",
    "\n",
    "    return updated_known_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe1695d-0bef-456c-9702-1bfaf56f9bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/jovyan/XAI/project/gpt2_model.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gradient_norm = torch.norm(torch.tensor(gradients[i]), p=1)\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.54it/s]\n"
     ]
    }
   ],
   "source": [
    "different_tokenization = 0\n",
    "gradient_norm_dot_product = []\n",
    "gradient_norm_probes_needed = []\n",
    "\n",
    "\n",
    "for sentence_data in tqdm(extracted_sentences_data[:10]):\n",
    "    known_evidence = sentence_data[0]\n",
    "    sentence = sentence_data[1]\n",
    "    correct_word = sentence_data[2]\n",
    "    foil_word = sentence_data[3]\n",
    "\n",
    "    saliency_map = gpt2model.get_contrastive_gradient_norm(sentence, correct_word, foil_word)\n",
    "    extracted_words = [explanation[0].strip() for explanation in saliency_map]\n",
    "    explanation = [explanation[1] for explanation in saliency_map]\n",
    "\n",
    "    if sentence.split(\" \") != extracted_words:\n",
    "        known_evidence = match_evidence_with_tokenization(sentence.split(\" \"), extracted_words, known_evidence)\n",
    "\n",
    "    updated_known_evidence = match_evidence_with_tokenization(sentence.split(\" \"), extracted_words, known_evidence)\n",
    "    gradient_norm_dot_product.append(compute_mean_dot_product([explanation], [updated_known_evidence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8492186b-9d0a-43c2-976b-81d40762837a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1572659759070616"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(gradient_norm_dot_product).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
